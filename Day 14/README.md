Hi Kaggler,

Youâ€™ve made it to the end of the Intermediate ML course! Today, youâ€™ll finish the final two lessons.

ðŸ“‹ Todayâ€™s Assignment
Read this tutorial (from Lesson 6 of the Intermediate ML course)
Complete this exercise (from Lesson 6 of the Intermediate ML course)
Read this tutorial (from Lesson 7 of the Intermediate ML course)
Complete this exercise (from Lesson 7 of the Intermediate ML course)
ðŸ’¡ What Youâ€™ll Learn
In Lesson 6 (XGBoost), you will learn how to build and optimize models with gradient boosting. This method dominates many Kaggle competitions and achieves state-of-the-art results on a variety of datasets.

In Lesson 7 (Data Leakage), you will learn what data leakage is and how to prevent it. If you don't know how to prevent it, leakage will come up frequently, and it will ruin your models in subtle and dangerous ways. So, this is one of the most important concepts for practicing data scientists.

Youâ€™ve come a long way, and you should be proud of all of your hard work and progress. Over the next couple of weeks, youâ€™ll apply what youâ€™ve learned in an exclusive competition, open only to others enrolled in the 30 Days of ML program. More on that, including how to get started with the competition, tomorrow!